PART A:
1. Downloaded CSV files to desktop
2. mkdir SANDOVAL-POWERS_Project1	
3. mkdir DOM
	mkdir CAST
4. less -S ORIGINALFILE.csv
5. cp DOMFILE.csv DOM
	cp CASTFILE.csv	CAST

PART B:
1. head -1 DOMFILE.csv > DOM_header.txt
	nano DOMFILE.csv and then ^K to delete first line 
2. sort -k17n DOMFILE.csv | uniq > DOM_lat_uniq.txt
	"sorted file based on latitude coordinates which I found by opening 
	the header file and counting over columns until I saw latitude. 
	-k is a key finder so -k17n told it to find column 17 and sort based
	off that column on the DOMFILE. Since this was sorted I was able
	to pipe and remove duplicated entries using uniq"
3. sort -k18n DOM_lat_uniq.txt | uniq > DOM_lat_long_uniq.txt
	"longitude records were 18 columns over so did the same thing as 
	above and just changed the sort command to find column 18"
4. wc -l DOMFILE.csv
	Original DOM file lines = 8481
wc -l DOM_lat_long_uniq.txt
	DOM lat long uniq file lines = 8389
	
Difference of 92 lines of duplicated data entries
0.01085 or 1.085% of the original file was duplicated lines of data

5. grep "USNM" DOM_lat_long_uniq.txt > DOM_USNM.txt
	This command told it to search the lat long file for any lines that
	contained USNM and send the output to the DOM_USNM file.
6. wc -l DOM_USNM.txt
	DOM USNM file lines = 4346
wc -l DOM_lat_long_uniq.txt 
	lat long uniq file lines = 8389

Proportion of records Smithsonian records = 52%

7. awk 'FS="\t" {print $17, $18}' DOm_USNM.txt > DOM_USNM_lat_long.txt
	Isolated the 17th and 18th columns and printed them in a file. 
	'FS="\t" tells awk that the file is delimited by tabs
8. grep -v "^\s*$" DOM_USNM_lat_long.txt > DOM_lat_long_cleaned.txt
	This command said to keep everything but lines that contained a space
	on the lat long file and send to a cleaned file. 
9. Repeated the following steps in Part B for the CSV file in the CAST folder
	Original CAST file lines = 1676
	lat long CAST file lines = 1676

	No duplicated records in the CAST records

	lat long CAST file lines = 1676
	CAST USNM file lines = 1317 

	79% of Smithsonian records are part of these collections for CAST

PART C: 
1. cat DOM/DOM_lat_long_cleaned.txt CAST/CAST_lat_long_cleaned.txt > Lat_Long_
USNM_combined.txt

	This command was executed in the Project1 directory and combined the
	cleaned records located in the DOM directory and the CAST directory
	and sent to a file Lat_Long_....
2. nano SANDOVAL-POWERS.README.txt

 
